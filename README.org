#+TITLE: Kopie bezpieczeństwa
#+SUBTITLE: Projektowanie systemów bezpieczeństwa
#+AUTHOR: Patryk Gronkiewicz 164157, Piotr Krawiec 164165
#+EMAIL: 164157@stud.prz.edu.pl, 164165@stud.prz.edu.pl
#+OPTIONS: toc:nil
#+LANGUAGE: pl

* Wybrane programy
** Rsync + tar
Jest to najprostsza opcja dostępna na praktycznie każdym urządzeniu z Linuxem. Rozwiązanie to składa się w rzeczywistości z dwóch programów - /rsync/ oraz /tar/. Pierwszy z nich służy do kopiowania plików lokalnie oraz na serwery zdalne, natomiast drugi generuje pojedynczy plik z naszego backupu. /tar/ pozwala także na zmniejszenie rozmiaru kopii dzięki wykorzystaniu kompresji.

W naszym przypadku przydatne okazało się też polecenie /date/, które posłużyło do nadawania unikalnych nazw kolejnym kopiom zapasowym. Dodatkowo zastosowano /cron-a/, który pozwolił nam na zaplanowanie wykonywania kopii.
** Duplicati
W naszym zestawie rozwiązań jest to najbardziej multiplatformowe i proste do użycia rozwiązanie - jest proste do ustawienia zarówno na Windowsie, Linuxie, jak i macOS. Po zainstalowaniu go możemy zarządzać wszystkimi jego ustawieniami z pomocą interfejsu przeglądarkowego. Jako jedyne niestety nie ma opcji ustawiania z pomocą linii komend, co można rozwiązać z pomocą zewnętrznych pakietów dostępnych np. w /pip/-ie.
** Restic
Rozwiązanie najbardziej rozbudowane, lecz wymagające więcej doświadczenia w konfiguracji. Pozwala na stosunkowo proste skonfigurowanie retencji, połączenia do mniej typowych chmur takich jak S3, lecz nie uruchamia się automatycznie. Do odpowiedniego działania wymagane jest, aby użyć planowania backupów przez CRON lub =systemd-timers=.

Twórcy twierdzą, że jest:
+ prosty w obsłudze
+ Efektywny
+ Bezpieczny
+ Weryfikowalny
+ Wolny jak w wolności[fn:freedom]
[fn:freedom] (en. /Free as in freedom/ - Richard Matthew Stallman) - dotyczy wolnościowego podejścia do oprogramowania

* Sposób działania
** Rsync + tar

W najprostszej konfiguracji backup możemy wykonać dokonując kompresji danych (z pomocą /tar/), a następnie wysyłając je w dowolne miejsce z /rsync/. Przykładowa konfiguracja znajduje się poniżej:

#+NAME:
#+BEGIN_SRC shell
tar cazf /tmp/backup.tar.gz /media && rsync /tmp/backup.tar.gz /mnt/$(date +%s).tar.gz
#+END_SRC

Uruchomienie powyższego skryptu utworzy tymczasowy plik ~backup.tar.gz~, który zostanie umieszczony w katalogo ~/mnt~. Plik tymczasowy zostanie usunięty po ponownym uruchomieniu komputera, jednak w przypadku uruchamiania go na serwerach w celu oszczędzania miejsca.

Aby odzyskać dane wykonujemy podobne polecenia, lecz w odwrotnej kolejności.

** Duplicati

Działający w tle serwis Duplicai sprawdza czy warunki uruchomienia danej konfiguracji zostały spełnione. Jeżeli tak, uruchamiany jest proces wykonujący kopię. W przypadku wystąpienia błędu otrzymujemy powiadomienie o niepowodzeniu. Informacja o tym, kiedy wykonana została odstatnia kopia zapasowa dostępna jest z poziomu interfejsu przeglądarkowego. Jest on dostępny z hosta na porcie 8200.

Format w jakim Duplicati tworzy backupy oparty jest na blokach. Oznacza to, że Duplicati nie kopiuje bezpośrednio plików w wybrane miejsce, a dzieli i łączy je w mniejsze bloki stałej długości. Nazwy stworzonych bloków są tworzone tak, aby nie niosły za sobą informacji o dacie stworzenia ani zawartości, dzięki czemu można je bezpiecznie przechowywać w chmurze. Informacja o tym, jakie pliki znajdują się w danym bloku znajduje się w bazie danych, która zostaje stworzona dla każdej z kopii zapasowych (zarówno lokalnie, jak i zdalnie).

#+NAME: Fragment pliku filenames.json zawierającego informacje o przechowywanych plikach
#+BEGIN_SRC json
[
  {
  "type": "Folder",
  "path": "C:\\data\\"
  },
  {
  "type": "File",
  "path": "C:\\data\\mydoc.txt",
  "size": 4096,
  "hash": "qaFXpxVTuYCuibb9P41VSeVn4pIaK8o3jUpJKqI4VF4="
  },
  {
  "type": "File",
  "path": "C:\\data\\myvideo.mp4",
  "size": 215040,
  "hash": "4sGwVN/QuWHD+yVI10qgYa4e2F5M4zXLKBQaf1rtTCs=",
  "blocklists": [ "Uo1f4rVjNRX10HkxQxXauCrRv0wJOvStqt9gaUT0uPA=" ]
  }
]
#+END_SRC

Skąd Duplicati wie, że plik został zmieniony? Oblicza jego /hash/ i umieszcza go w nowym pliku filelist.json w celu późniejszego porównania podczas tworzenia kolejnej kopii. Duplicati tworząc blok danych /dblock/ dodatkowo dodaje informacje o przechowanych w nich /hash/ w bazie /dindex/. [fn:: https://www.duplicati.com/articles/Backup-Process/] Plik filelist.json tworzony jest dla każdej stworzonej kopii, pozwala to na szybkie odtworznie dowolnego stanu plików, ponieważ plik ten zawiera informacje, w których blokach szukać danych wersji pliku.

Aby zapewnić dodatkowe bezpieczeństwo Duplicati sugeruje, aby szyfrować
wszystkie dane. Aplikacja automatycznie generuje hasło i je zapisuje, a my tak
wygenerowaną konfigurację (z zapisanymi hasłami) możemy zapisać w bezpiecznym
miejscu (np. Secure Notes w Bitwarden). Szyfrowanie bloków daje nam pewność, że
nawet dostawca usług chmurowych nie będzie w stanie podejrzeć jakie dane
przechowyujemy na jego serwerze.

#+CAPTION: Schemat blokowy procesu tworzenia kopii przez Duplicati
[[./img/duplicati/duplicati-processing-files-and-folders.png]]

** Restic
Restic działa na zasadzie kopii przyrostowych - dzięki temu jest zdolny do tworzenia stosunkowo małych kopii nawet przy dużych ilościach danych. Pozwala także na łatwe przywrócenie kopii przez interfejs terminala. Jego działanie jest analogiczne do podmontowania np. pendrive.

Kopie zapasowe prowadzone przez Restica można bardzo prosto zaszyfrować, jak i wysyłać na różne rodzaje pamięci sieciowych - od S3, przez SSHFS i WebDav aż po rozwiązania typowo konsumenckie jak Google Drive, Mega czy OneDrive. W przypadku części integracji wymagane jest użycie Rclone, który jest interfejsem do połączenia się z daną chmurą. Bez najmniejszego problemu jest także dostępny backup lokalny, który tworzony jest w niemal identyczny sposób jak ten chmurowy.

Każda kopia zapasowa ma swoje repozytorium - miejsce, gdzie pliki odpowiadające za kopię są trzymane. Jest to miejsce, którego nie chcemy stracić (ale i tak prawdopowodobnie mamy inny backup, jeśli trzymamy się zasad 😉).
* Retencja
** Rsync + tar

Ponieważ rsync wyłącznie wysyła pliki do danej lokalizacji, to użytkownik jest odpowiedzialny za zarządzaniem plikami na zdalnym serwerze. Najprostszym sposobem na zarządzaniem nimi jest umieszczenie skryptu, który będzie realizował dwolną politykę retencji. Przykładowy skrypt został opisany poniżej.

#+NAME: Przykład retencji - usuwa kopie starsze niż 30 dni
#+BEGIN_SRC shell
find /mnt -name '*tar.gz' -mtime +30 -delete -print
#+END_SRC

Skrpt ten wyszukuje wszystkie pliki z rozszerzeniem ~.tar.gz~ i spośród nich uwuwa te, utworzone wcześniej niż 30 dni temu.

** Duplicati

Duplicati oferuje zarówno gotowe tryby retencji, jak i pozwala na dostosowanie jej. Możemy wybierać spośród następujących trybów:

- /Keep all backups/ - żadne dane nie zostają usunięte (utrzymywane są wszystkie wersje plików). Kopia zapasowa będzie rosła z każdą zmianą.
- /Delete backups that are older than/ - usuwa wszystkie kopie plików starsze niż podany czas, o ile znaleziona zostanie co najmniej jedna nowsza wersja danej kopii.
- /Keep a specific number of backups/ - najstarsze kopie ponad podaną ilość są usuwane.
- /Smart backup retention/ - tryb smart, kopie zostają usuwane automatycznie jeżeli będzie ich więcej niż:
    - Po jednej kopii na każdy z ostatnich 7 dni
    - Po jednej kopii na każdy z ostatnich 4 togodnii
    - Po jednej kopii na każdy z ostatnich 12 miesięcy
    - Przy czym zawsze istnieć będzie co najmniej jedna kopia danych
- /Custom backup retention/ - pozwala na ustawienie dowolnej kombinacji w formacie: =NUMER= =CZAS=:=NUMER= =CZAS=. Np. 1W:1D, pozostawia na następne 7 dni jedną kopię z każdego dnia.

** Restic
Retencję w Resticu można bardzo łatwo skonfigurować. Standardowo parametry do niej są podawane podczas wywołania komendy. Tymi argumentami są:
+ =--keep-daily n=
+ =--keep-weekly n=
+ =--keep-monthly n=
+ =--keep-yearly n=
Opisują ile kopii z danego okresu mamy minimalnie trzymać. Dla np. =--keep-daily 3= będziemy zawsze mieli ostatnie 3 kopie z danego dnia. Jeśli np. w środę zrobimy cztery kopie numerowane chronologicznie od najstarszych - $A$, $B$, $C$ i $D$ - przy takim ustawieniu będziemy mieli dostęp tylko do kopii $B$, $C$ i $D$. Analogicznie działa to dla pozostałych argumentów, które możemy dodać przy wywołaniu funkcji.
* Typy kopii
** Rsync + tar

Rsync + tar pozwala wyłącznie na jeden typ kopii - pełne. Z każdym uruchomieniem backupu stworzona zostanie pełna kopia danych. Największą wadą takiego rozwiązania jest to, że będzie on rósł z każdą kopią (nawet jeżeli nie dokonaliśmy żadnych zmian), co może doprowadzić do wyczerpania przestrzeni dyskowej znacznie szybciej od innych opcji. Zdecydowaną zaletą jest prostota i łatwość przywrócenia kopii - wystarczy przenieść i rozpakować kopię.

** Duplicati
** Restic
Jedyną opcją w tym wypadku jest kopia pełna podczas inicjalizacji repozytorium, a następnie kopie przyrostowe. Pozwala to na ,,cofnięcie się w czasie'' o niemal dowolne okno, ponieważ mało prawdopodobne jest, że za rok będziemy potrzebowali kopii z dokładnością co do dnia.
* Chmura
** Rsync + tar

Rsync nie wspiera umieszczania plików na chmurze, ponieważ wykorzystuje ssh do kopiowania plików do zdalnych katalogów (czego chmury nie wspierają). Istnieje jednak alternatywa, właśnie dla rozwiązań chmurowych - RClone [fn:: https://github.com/rclone/rclone]. Pozwala on na synchronizację danych z chmurą, a także zamontowanie chmury jako katalogu. Uruchamiając =rclone config= zostaniemy przeprowadzeni przez proces konfiguracji nowej chmury, którą później możemy wykorzystać do stworzenia kopii. Poniżej znajduje się przykład z dokumentacji:

#+CAPTION: Konfiguracja Backblaze B2 w rclone
#+BEGIN_SRC text
rclone config

No remotes found - make a new one
n) New remote
q) Quit config
n/q> n
name> remote
Type of storage to configure.
Choose a number from below, or type in your own value
[snip]
XX / Backblaze B2
   \ "b2"
[snip]
Storage> b2
Account ID or Application Key ID
account> 123456789abc
Application Key
key> 0123456789abcdef0123456789abcdef0123456789
Endpoint for the service - leave blank normally.
endpoint>
Remote config
--------------------
[remote]
account = 123456789abc
key = 0123456789abcdef0123456789abcdef0123456789
endpoint =
--------------------
y) Yes this is OK
e) Edit this remote
d) Delete this remote
y/e/d> y
#+END_SRC

** Duplicati

Duplicati zostało zbudowane z myślą o tworzeniu zadalnych kopii. Wspiera standardowe protokoły FTP, SSH i WebDAV. Ponadto dobrze integruje się z serwisami oferującymi przestrzeń dyskową typu Microfost OneDrive, Google Drive, Mega itp. oraz wspiera serwisy chmurowe: Backblaze B2, Google Cloud Storage, Amazon S3. [fn:: https://www.duplicati.com/] Przykłady integracji z chmurą znajdują się poniżej.
*** Backblaze B2

Integracja z Backblaze B2 jest bardzo prosta, sprowadza się do ustawienia B2 jako miejsca, gdzie będziemy dane przechowywać, stworzeniu bucketa i wprowadzeniu kluczy dostępu do niego. Proces tworzenia klucza i konfiguracji Duplicati został umieszczony poniżej.

#+CAPTION: Tworzenie bucketa w Backblaze B2
[[./img/duplicati/backblaze/6.png]]

Po utworzeniu bucketa, należy stworzyć klucz aplikacji, który pozwoli Duplicati na dostęp do chmury.

#+CAPTION: Tworzenie klucza dostępu
[[./img/duplicati/backblaze/7.png]]

Wygenerowany klucz należy natychmiast wprowadzić do aplikacji, gdyż nie można go odczytać drugi raz - należałoby stworzyć nowy klucz dostępu.

#+CAPTION: Wygenerowany klucz
[[./img/duplicati/backblaze/8.png]]

Tak wygenerowny klucz wprowadzamy do aplikacji.

*** Google Cloud Storage

W przypadku Google Cloud Storage wymagania są podobne. Jednak, ponieważ interfejs Google Cloud jest znacznie bardziej rozbudowany, Duplicati oferuje automatyczne wygenerowanie kluczy dostępu korzystając z OAuth, pozostała część konfiguracji przebiega identycznie jak w przypadku Backblaze B2. Zacząć należy tak jak poprzednio, od utworzenia bucketa w Google Cloud Storage.

#+CAPTION: Stworzenie bucketa w Google Cloud Storage
[[./img/duplicati/google/1.png]]

Następnie należy wejść w link [[https://duplicati-oauth-handler.appspot.com?type=gcs]]. Wtedy po naciśnięciu przycisku (rysunek poniżej), należy się zalogować do konta Google.

#+CAPTION: Autoryzacja w GCS
[[./img/duplicati/google/3.png]]

Po autozyzacji uzyskany AuthId wpisujemy jak na obrazku poniżej.

#+CAPTION: Konfiguracja GCS w Duplicati
[[./img/duplicati/google/4.png]]

** Restic
Restic ma bardzo rozbudowaną integrację z chmurą - zarówno bezpośrednią, jak i z pomocą narzędzi takich jak rclone. Najprościej integruje się z /object storage/[fn:object_storage]. Są to chmury nakierowane na trzymanie wielu małych plików.
[fn:object_storage] - przestrzeń obiektowa, pozwala na proste trzymanie wielu małych plików i jest właśnie w tym celu zoptymalizowane. ,,Klasyczne'' chmury, które bezpośrednio udostępniają dysk nazywane są /block storage/.

Autorzy chwalą się natywnym wsparciem dla kilkunastu różnych chmur, które można podzielić na trzy różne kategorie:
1. Backup lokalny - działa na dysku podłączonym do komputera
2. Backup do block storage - Autorzy dostarczają obsługę protokołu SFTP (/SSH File Transfer Protocol/), a także własny serwer obsługujący HTTP(S).
3. Backup do object storage - wspierane jest wiele najbardziej popularnych chmur takich jak AWS S3, Backblaze B2, Azure Blob Storage, Wasabi, a także opcje selfhosted w postaci Minio i OpenStack Swift.

Dodatkowe opcje dostarcza Rclone, który pozwala zamontować nam ponad 50 różnych chmur, a co za tym idzie istotnie rozszerzyć funkcjonalność naszego rozwiązania. Dzięki ścisłej integracji nie ma potrzeby podmontowywania danej chmury pod folder, co działa na naszą korzyść ze względu na jeszcze lepsze zabezpieczenie przed Ransomware.
